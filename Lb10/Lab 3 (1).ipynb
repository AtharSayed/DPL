{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21912c9a-933d-4ab0-9d80-9263c71a7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.2191 - loss: 2.9925 - val_accuracy: 0.2426 - val_loss: 2.7665\n",
      "Epoch 2/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.2861 - loss: 2.5906 - val_accuracy: 0.3372 - val_loss: 2.3556\n",
      "Epoch 3/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.3657 - loss: 2.2314 - val_accuracy: 0.3676 - val_loss: 2.2078\n",
      "Epoch 4/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.3917 - loss: 2.0635 - val_accuracy: 0.3739 - val_loss: 2.1331\n",
      "Epoch 5/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.4143 - loss: 1.9602 - val_accuracy: 0.3960 - val_loss: 2.0714\n",
      "Epoch 6/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.4318 - loss: 1.8877 - val_accuracy: 0.3960 - val_loss: 2.0597\n",
      "Epoch 7/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.4569 - loss: 1.7972 - val_accuracy: 0.3997 - val_loss: 2.0491\n",
      "Epoch 8/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.4763 - loss: 1.7318 - val_accuracy: 0.4060 - val_loss: 2.0192\n",
      "Epoch 9/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.4875 - loss: 1.6776 - val_accuracy: 0.4097 - val_loss: 1.9875\n",
      "Epoch 10/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5022 - loss: 1.6389 - val_accuracy: 0.4139 - val_loss: 1.9765\n",
      "Epoch 11/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5216 - loss: 1.5871 - val_accuracy: 0.4181 - val_loss: 1.9870\n",
      "Epoch 12/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5363 - loss: 1.5202 - val_accuracy: 0.4202 - val_loss: 1.9832\n",
      "Epoch 13/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.5534 - loss: 1.4628 - val_accuracy: 0.4175 - val_loss: 1.9843\n",
      "Epoch 14/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.5680 - loss: 1.4193 - val_accuracy: 0.4112 - val_loss: 2.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.5754 - loss: 1.3779 - val_accuracy: 0.4112 - val_loss: 2.0135\n",
      "Epoch 16/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.5840 - loss: 1.3607 - val_accuracy: 0.4034 - val_loss: 2.0231\n",
      "Epoch 17/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.6000 - loss: 1.3107 - val_accuracy: 0.4181 - val_loss: 2.0272\n",
      "Epoch 18/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6224 - loss: 1.2557 - val_accuracy: 0.4181 - val_loss: 2.0463\n",
      "Epoch 19/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.6344 - loss: 1.2100 - val_accuracy: 0.4186 - val_loss: 2.0594\n",
      "Epoch 20/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.6500 - loss: 1.1507 - val_accuracy: 0.4097 - val_loss: 2.0865\n",
      "Epoch 21/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6671 - loss: 1.1018 - val_accuracy: 0.4091 - val_loss: 2.1056\n",
      "Epoch 22/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.6856 - loss: 1.0634 - val_accuracy: 0.4181 - val_loss: 2.1351\n",
      "Epoch 23/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6956 - loss: 1.0205 - val_accuracy: 0.4081 - val_loss: 2.1611\n",
      "Epoch 24/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7143 - loss: 0.9715 - val_accuracy: 0.4023 - val_loss: 2.1920\n",
      "Epoch 25/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7262 - loss: 0.9345 - val_accuracy: 0.3981 - val_loss: 2.2493\n",
      "Epoch 26/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.7412 - loss: 0.8926 - val_accuracy: 0.3997 - val_loss: 2.2872\n",
      "Epoch 27/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.7551 - loss: 0.8493 - val_accuracy: 0.4044 - val_loss: 2.2743\n",
      "Epoch 28/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.7591 - loss: 0.8352 - val_accuracy: 0.4044 - val_loss: 2.3195\n",
      "Epoch 29/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.7737 - loss: 0.7920 - val_accuracy: 0.4028 - val_loss: 2.3567\n",
      "Epoch 30/30\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.7907 - loss: 0.7411 - val_accuracy: 0.3908 - val_loss: 2.4045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c5f38be1d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# File Reading with try and except \n",
    "try:\n",
    "    with open(\"F:\\M.Tech_CollgeMaterials\\DPL\\Lb10\\data\\shakesphere.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()  # text variable stores the data from the shakespeare.txt file \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: shakespeare.txt not found. Please download the dataset and place it in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "text = text.lower()   # the text is converted to lowercase with .lower function and the state of the variable is updated \n",
    "text = text.translate(str.maketrans('', '', string.punctuation)) # \n",
    "vocab = sorted(list(set(text)))\n",
    "char_to_index = {u:i for i, u in enumerate(vocab)}\n",
    "index_to_char = np.array(vocab)\n",
    "\n",
    "seq_length = 50\n",
    "data = [char_to_index[c] for c in text]\n",
    "n = len(data) - seq_length\n",
    "train_data = data[:int(n * 0.8)]\n",
    "val_data = data[int(n * 0.8):int(n * 0.9)]\n",
    "test_data = data[int(n * 0.9):]\n",
    "\n",
    "def create_sequences(data):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(0, len(data) - seq_length, 1):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "train_sequences, train_labels = create_sequences(train_data)\n",
    "val_sequences, val_labels = create_sequences(val_data)\n",
    "test_sequences, test_labels = create_sequences(test_data)\n",
    "\n",
    "\n",
    "# 2. Model Building (modified to use SimpleRNN)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(len(vocab), 50, input_length=seq_length),\n",
    "    keras.layers.SimpleRNN(128, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(128),\n",
    "    keras.layers.Dense(len(vocab), activation='softmax')\n",
    "])\n",
    "\n",
    "# 3. Model Compilation (same as before)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Training (Reduced epochs for faster runtime - adjust as needed)\n",
    "model.fit(train_sequences, train_labels, epochs=30, batch_size=128, validation_data=(val_sequences, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be0d6e0-8a21-413e-b478-d3076564da87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Generated Text:\n",
      " qnsovjwlmeway9fndqb5f45i\n",
      "rimlv1t7opc4jglqzzlcex4xuing\n",
      "  when \n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_index, length):\n",
    "    # Initialize with a sequence of seq_length random characters.\n",
    "    generated_text = [np.random.randint(0, len(vocab)) for _ in range(seq_length)]  \n",
    "    generated_text.append(start_index) # Add the actual starting index\n",
    "\n",
    "    for _ in range(10):\n",
    "        input_seq = np.array([generated_text[-seq_length:]]) # correct slicing\n",
    "        prediction = model.predict(input_seq)\n",
    "        next_index = np.argmax(prediction[0])\n",
    "        generated_text.append(next_index)\n",
    "    return \"\".join([index_to_char[i] for i in generated_text]) # corrected index\n",
    "\n",
    "\n",
    "start_index = np.random.randint(0, len(vocab))\n",
    "generated = generate_text(model, start_index, 200)\n",
    "print(\"Generated Text:\\n\", generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674e59f-cfe9-456e-8355-68b2b47e89d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
